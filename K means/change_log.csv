No.,Change,Reason for Change,Estimated Time (mins),Difficulty (1-10)
1,Loaded dataset into a dataframe (Live.csv),Importing the dataset is the first step in any machine learning project. This allows us to inspect and manipulate the data as needed.,15,2
2,Used df.describe() to get summary statistics,"Helps understand dataset characteristics, such as mean, standard deviation, and distribution of numerical features. This step is useful for detecting outliers and understanding feature ranges.",2,2
3,"Dropped unnecessary columns (Column1, Column2, Column3, Column4)",Removing irrelevant or redundant columns reduces memory usage and improves the efficiency of data processing and model training.,2,2
4,Checked for unique values in status_id and status_published,"Understanding categorical variables before encoding ensures that we do not encode unnecessary columns, reducing dimensionality and improving model performance.",2,2
5,Dropped status_published and status_id,"Since these columns contained unique identifiers, they do not contribute to meaningful clustering patterns and could introduce noise in the model. Removing them helps improve clustering accuracy.",2,2
6,Checked for missing values using df.isna().sum(),Missing values can cause errors or biases in the clustering model. Checking for missing values ensures that we handle them properly before proceeding.,2,2
7,Encoded status_type using LabelEncoder,Machine learning models cannot handle categorical text data directly. Encoding status_type into numerical format allows it to be used in the clustering algorithm.,5,3
8,Separated features (X) and target (y),"Splitting features (X) and the target variable (y) is a standard practice to prepare data for training and evaluation. In this case, status_type was chosen as the target variable.",2,2
9,Scaled the features using StandardScaler,"Feature scaling ensures that all numerical values are within the same range, preventing larger-valued features from dominating the clustering process. Standardization helps improve model accuracy.",3,3
10,Checked the inertia for k = 1 to 10,The inertia value helps determine the optimal number of clusters by measuring how well the data points fit within their assigned clusters.,4,4
11,Trained a KMeans clustering model with k=3,The K-Means algorithm groups data into k clusters by minimizing intra-cluster variance. A k value of 3 was chosen based on the Elbow Method.,5,4
12,Visualized the clusters using matplotlib and marked centroids,"Visualization helps interpret how well the clusters are formed. Marking centroids provides insight into cluster centers, making patterns clearer.",5,4
